{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Italian Financial Challenge\n",
    "\n",
    "**Student Name:** Simone Prezioso, Claudio De Acutis, Alexandre Viallard, Alessandro Vertunni \n",
    "\n",
    "**Challenge:** Financial Health Classification\n",
    "\n",
    "**Date:** 5/02/2026\n",
    "\n",
    "---\n",
    "\n",
    "## Instructions\n",
    "\n",
    "This template provides a suggested structure for your challenge solution. You can adapt it to your needs, but make sure to cover all required sections:\n",
    "\n",
    "1. Problem Statement and Objectives\n",
    "2. Data Loading and Exploration\n",
    "3. Data Preprocessing\n",
    "4. Feature Engineering\n",
    "5. Model Development\n",
    "6. Model Evaluation\n",
    "7. Interpretation and Business Insights\n",
    "8. Conclusions and Future Work\n",
    "\n",
    "**Remember:**\n",
    "- Document your thought process with markdown cells\n",
    "- Comment your code clearly\n",
    "- Create visualizations to support your insights\n",
    "- Interpret results in business terms\n",
    "- Check the evaluation rubric to ensure you meet all criteria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Problem Statement and Objectives\n",
    "\n",
    "**Challenge:** \n",
    "We chose the \"Financial Health Classification\" in order to push ourselves outside our comfort zone just enough to learn as much as much as possible while working on an amazingly interesting project, we didn't want to go for something too easy such as task 1 or something that would've required time that we didnt have such as task 3.\n",
    "\n",
    "**Objective:** \n",
    "Our goal is to build a model capable of confidently classifying companies into 4 distinct categories based on their financial \"health\":\n",
    "A: Excellent financial health\n",
    "B: Good financial health\n",
    "C: Moderate risk\n",
    "D: High risk / Distressed\n",
    "\n",
    "**Success Criteria:** \n",
    "We can divide our criteria into 3 categories:\n",
    "1) Metrics: Weighted F1-score â‰¥ 0.65 on the held-out test set\n",
    "2) Errors: No extreme ordinal errors, specifically no A â†’ D or D â†’ A misclassifications in the confusion matrix\n",
    "3) Interpretability: Clear and class-specific feature importance analysis (e.g. per-class SHAP values or one-vs-rest explanations), with financially coherent drivers for classes A, B, C, and D.\n",
    "\n",
    "**Approach:** [Briefly outline your planned approach]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn as skl\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import imblearn as imb\n",
    "import shap \n",
    "import plotly as px\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Exploration\n",
    "\n",
    "Load the training data and perform initial exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "train_df = pd.read_csv('../data/processed/train_data.csv')\n",
    "\n",
    "print(f\"Dataset shape: {train_df.shape}\")\n",
    "print(f\"\\nColumns: {train_df.columns.tolist()}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic information\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "missing_values = train_df.isnull().sum()\n",
    "missing_pct = (missing_values / len(train_df)) * 100\n",
    "\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Count': missing_values,\n",
    "    'Percentage': missing_pct\n",
    "})\n",
    "missing_df = missing_df[missing_df['Missing Count'] > 0].sort_values('Missing Count', ascending=False)\n",
    "\n",
    "print(\"Missing Values:\")\n",
    "print(missing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target variable analysis\n",
    "# TODO: Uncomment the relevant section for your challenge\n",
    "\n",
    "# For Challenge 1: Bankruptcy Prediction\n",
    "# print(\"\\nBankruptcy Distribution:\")\n",
    "# print(train_df['bankruptcy_next_year'].value_counts())\n",
    "# print(f\"\\nBankruptcy rate: {train_df['bankruptcy_next_year'].mean():.2%}\")\n",
    "\n",
    "# For Challenge 2: Financial Health Classification\n",
    "# print(\"\\nFinancial Health Distribution:\")\n",
    "# print(train_df['financial_health_class'].value_counts().sort_index())\n",
    "# print(\"\\nPercentages:\")\n",
    "# print(train_df['financial_health_class'].value_counts(normalize=True).sort_index())\n",
    "\n",
    "# For Challenge 3: Revenue Forecasting\n",
    "# print(\"\\nRevenue Change Statistics:\")\n",
    "# print(train_df['revenue_change'].describe())\n",
    "# print(f\"\\nMissing revenue_change: {train_df['revenue_change'].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis (EDA)\n",
    "\n",
    "Create visualizations to understand the data better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create visualizations\n",
    "# - Distribution plots for key financial ratios\n",
    "# - Correlation heatmap\n",
    "# - Target variable by sector, region, year, etc.\n",
    "# - Box plots for outlier detection\n",
    "\n",
    "# Example: Correlation heatmap\n",
    "numeric_cols = train_df.select_dtypes(include=[np.number]).columns\n",
    "correlation_matrix = train_df[numeric_cols].corr()\n",
    "\n",
    "plt.figure(figsize=(14, 10))\n",
    "sns.heatmap(correlation_matrix, annot=False, cmap='coolwarm', center=0)\n",
    "plt.title('Correlation Matrix of Numeric Features')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Insights from EDA:**\n",
    "\n",
    "TODO: Document your key findings\n",
    "- \n",
    "- \n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing\n",
    "\n",
    "Handle missing values, outliers, and prepare data for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy for preprocessing\n",
    "df_processed = train_df.copy()\n",
    "\n",
    "# TODO: Handle missing values\n",
    "# - Decide on imputation strategy (median, mean, by group, etc.)\n",
    "# - Document your rationale\n",
    "\n",
    "# TODO: Handle outliers\n",
    "# - Identify outliers (IQR, winsorization, etc.)\n",
    "# - Decide on treatment strategy\n",
    "\n",
    "# TODO: Encode categorical variables\n",
    "# - One-hot encoding, label encoding, etc.\n",
    "\n",
    "print(\"Preprocessing complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Validation split\n",
    "# IMPORTANT: Use temporal split, not random!\n",
    "\n",
    "# For Challenges 1 & 2:\n",
    "# train_years = [2018, 2019, 2020]\n",
    "# val_year = 2021\n",
    "\n",
    "# For Challenge 3 (time series):\n",
    "# train_years = [2018, 2019]\n",
    "# val_year = 2020\n",
    "# test_year = 2021\n",
    "\n",
    "# TODO: Implement temporal split\n",
    "# df_train = df_processed[df_processed['fiscal_year'].isin(train_years)]\n",
    "# df_val = df_processed[df_processed['fiscal_year'] == val_year]\n",
    "\n",
    "print(\"Train/validation split complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling\n",
    "# IMPORTANT: Fit scaler on training data only!\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "\n",
    "# TODO: Choose and apply scaler\n",
    "# scaler = StandardScaler()  # or RobustScaler() for outlier resistance\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "print(\"Feature scaling complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering\n",
    "\n",
    "Create new features based on domain knowledge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Engineer features\n",
    "# Ideas:\n",
    "# - Financial ratios (if not already present)\n",
    "# - Year-over-year changes (growth rates)\n",
    "# - Interaction features\n",
    "# - Altman Z-Score or similar bankruptcy models\n",
    "# - Sector-relative features (company vs sector average)\n",
    "# - Temporal features (trends, volatility)\n",
    "\n",
    "# Example: Year-over-year change\n",
    "# df_processed = df_processed.sort_values(['company_id', 'fiscal_year'])\n",
    "# df_processed['roe_yoy_change'] = df_processed.groupby('company_id')['roe'].diff()\n",
    "\n",
    "print(\"Feature engineering complete!\")\n",
    "print(f\"Total features: {df_processed.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Engineered Features:**\n",
    "\n",
    "TODO: List and explain your engineered features\n",
    "1. \n",
    "2. \n",
    "3. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Development\n",
    "\n",
    "Train multiple models and compare performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import models\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, Ridge\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, \n",
    "    f1_score, roc_auc_score, accuracy_score,\n",
    "    mean_squared_error, mean_absolute_error, r2_score\n",
    ")\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "\n",
    "# For handling class imbalance (Challenges 1 & 2)\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "print(\"Model libraries imported!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Prepare X and y\n",
    "# feature_cols = [...]  # List your feature columns\n",
    "# target_col = 'bankruptcy_next_year'  # or 'financial_health_class' or 'revenue_change'\n",
    "\n",
    "# X_train = df_train[feature_cols]\n",
    "# y_train = df_train[target_col]\n",
    "# X_val = df_val[feature_cols]\n",
    "# y_val = df_val[target_col]\n",
    "\n",
    "print(\"Data prepared for modeling!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Train baseline model\n",
    "# For classification: Logistic Regression\n",
    "# For regression: Linear Regression\n",
    "\n",
    "# Example for Challenge 1 (Bankruptcy):\n",
    "# baseline_model = LogisticRegression(random_state=RANDOM_STATE, class_weight='balanced')\n",
    "# baseline_model.fit(X_train_scaled, y_train)\n",
    "# y_pred_baseline = baseline_model.predict(X_val_scaled)\n",
    "\n",
    "# print(\"Baseline Model Performance:\")\n",
    "# print(classification_report(y_val, y_pred_baseline))\n",
    "# print(f\"F1-Score: {f1_score(y_val, y_pred_baseline):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Train multiple models\n",
    "# - Random Forest\n",
    "# - XGBoost\n",
    "# - Gradient Boosting\n",
    "# - etc.\n",
    "\n",
    "# For classification with imbalance, consider:\n",
    "# - SMOTE oversampling\n",
    "# - Class weights\n",
    "# - Threshold tuning\n",
    "\n",
    "# Example for Random Forest with SMOTE:\n",
    "# smote = SMOTE(random_state=RANDOM_STATE)\n",
    "# X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# rf_model = RandomForestClassifier(\n",
    "#     n_estimators=100,\n",
    "#     max_depth=10,\n",
    "#     random_state=RANDOM_STATE\n",
    "# )\n",
    "# rf_model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "print(\"Advanced models trained!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Hyperparameter tuning\n",
    "# Use GridSearchCV or RandomizedSearchCV\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "\n",
    "# Example:\n",
    "# param_grid = {\n",
    "#     'n_estimators': [50, 100, 200],\n",
    "#     'max_depth': [5, 10, 15],\n",
    "#     'min_samples_split': [2, 5, 10]\n",
    "# }\n",
    "\n",
    "# grid_search = GridSearchCV(\n",
    "#     RandomForestClassifier(random_state=RANDOM_STATE),\n",
    "#     param_grid,\n",
    "#     cv=StratifiedKFold(n_splits=5),\n",
    "#     scoring='f1',\n",
    "#     n_jobs=-1\n",
    "# )\n",
    "# grid_search.fit(X_train_scaled, y_train)\n",
    "# best_model = grid_search.best_estimator_\n",
    "\n",
    "print(\"Hyperparameter tuning complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Evaluation\n",
    "\n",
    "Compare models and select the best one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create model comparison table\n",
    "# Compare all models on validation set using appropriate metrics\n",
    "\n",
    "# For Challenge 1: F1-Score, AUC-ROC, Precision, Recall\n",
    "# For Challenge 2: Weighted F1, Macro F1, Accuracy, Confusion Matrix\n",
    "# For Challenge 3: RMSE, MAE, MAPE, RÂ², Directional Accuracy\n",
    "\n",
    "# Example comparison:\n",
    "# models_comparison = pd.DataFrame({\n",
    "#     'Model': ['Baseline', 'Random Forest', 'XGBoost'],\n",
    "#     'F1-Score': [...],\n",
    "#     'AUC-ROC': [...],\n",
    "#     'Precision': [...],\n",
    "#     'Recall': [...]\n",
    "# })\n",
    "# print(models_comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Confusion Matrix (for classification)\n",
    "# from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "# ConfusionMatrixDisplay.from_estimator(best_model, X_val_scaled, y_val)\n",
    "# plt.title('Confusion Matrix - Best Model')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: ROC Curve (for binary classification)\n",
    "# from sklearn.metrics import RocCurveDisplay\n",
    "\n",
    "# RocCurveDisplay.from_estimator(best_model, X_val_scaled, y_val)\n",
    "# plt.title('ROC Curve - Best Model')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Selection:**\n",
    "\n",
    "TODO: Justify your final model choice\n",
    "- \n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Interpretation and Business Insights\n",
    "\n",
    "Explain the model and extract business value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Feature Importance\n",
    "# For tree-based models, use built-in feature importance\n",
    "# For other models, consider SHAP values\n",
    "\n",
    "# Example:\n",
    "# feature_importance = pd.DataFrame({\n",
    "#     'feature': feature_cols,\n",
    "#     'importance': best_model.feature_importances_\n",
    "# }).sort_values('importance', ascending=False)\n",
    "\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.barh(feature_importance['feature'][:15], feature_importance['importance'][:15])\n",
    "# plt.xlabel('Importance')\n",
    "# plt.title('Top 15 Most Important Features')\n",
    "# plt.gca().invert_yaxis()\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Error Analysis\n",
    "# - Which cases does the model misclassify/mispredicts?\n",
    "# - Are there patterns in the errors?\n",
    "# - How do errors vary by sector, size, region, etc.?\n",
    "\n",
    "# Example:\n",
    "# errors_df = df_val.copy()\n",
    "# errors_df['prediction'] = y_pred\n",
    "# errors_df['error'] = (errors_df['prediction'] != errors_df[target_col])\n",
    "\n",
    "# print(\"Error rate by sector:\")\n",
    "# print(errors_df.groupby('ateco_sector')['error'].mean().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Business Insights:**\n",
    "\n",
    "TODO: Translate technical findings into business language\n",
    "\n",
    "**Key Risk Factors** (for bankruptcy/health challenges):\n",
    "1. \n",
    "2. \n",
    "3. \n",
    "\n",
    "**Revenue Drivers** (for forecasting challenge):\n",
    "1. \n",
    "2. \n",
    "3. \n",
    "\n",
    "**Actionable Recommendations:**\n",
    "- \n",
    "- \n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Conclusions and Future Work\n",
    "\n",
    "Summarize findings and discuss limitations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary:**\n",
    "\n",
    "TODO: Summarize your work\n",
    "- \n",
    "- \n",
    "\n",
    "**Performance vs Targets:**\n",
    "\n",
    "TODO: Compare your results to challenge targets\n",
    "- My F1-Score: [X.XX] vs Target: [0.55-0.70]\n",
    "- ...\n",
    "\n",
    "**Model Limitations:**\n",
    "\n",
    "TODO: Discuss limitations honestly\n",
    "1. \n",
    "2. \n",
    "3. \n",
    "\n",
    "**Future Improvements:**\n",
    "\n",
    "TODO: What would you do with more time?\n",
    "1. \n",
    "2. \n",
    "3. \n",
    "\n",
    "**Lessons Learned:**\n",
    "\n",
    "TODO: Reflect on the experience\n",
    "- \n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Final Checklist\n",
    "\n",
    "Before submitting, verify:\n",
    "\n",
    "- [ ] All code cells execute without errors\n",
    "- [ ] Markdown cells explain each step clearly\n",
    "- [ ] Visualizations are clear and labeled\n",
    "- [ ] Feature importance is analyzed\n",
    "- [ ] Error analysis is performed\n",
    "- [ ] Business insights are provided\n",
    "- [ ] Model limitations are discussed\n",
    "- [ ] Code is well-commented\n",
    "- [ ] Results meet or exceed minimum performance targets\n",
    "- [ ] No data leakage (temporal split, proper scaling, etc.)\n",
    "- [ ] Citations for any external code/resources\n",
    "\n",
    "**Good luck with your challenge!** ðŸš€"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
